{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Event Discovery in Long-Horizon Video: Quick Demo\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/mesham/event-discovery/blob/main/notebooks/01_demo_quick.ipynb)\n",
    "\n",
    "This notebook demonstrates physics-inspired event discovery on autonomous driving video.\n",
    "\n",
    "**Runtime**: ~5 minutes on Colab GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Install dependencies and clone repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install opencv-python numpy matplotlib seaborn tqdm -q\n",
    "\n",
    "# Clone repository (if not already)\n",
    "import os\n",
    "if not os.path.exists('event-discovery'):\n",
    "    !git clone https://github.com/mesham/event-discovery.git\n",
    "    %cd event-discovery\n",
    "else:\n",
    "    %cd event-discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download Example Video\n",
    "\n",
    "We'll use a sample driving video with annotated events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download example video (placeholder - replace with actual dataset)\n",
    "!wget -O data/example_video.mp4 https://example.com/driving_video.mp4 -q\n",
    "!wget -O data/annotations.json https://example.com/annotations.json -q\n",
    "\n",
    "print(\"Downloaded example video and annotations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Run Hierarchical Energy Method\n",
    "\n",
    "Our main physics-inspired approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src')\n",
    "\n",
    "from methods.hierarchical_energy import HierarchicalEnergyMethod, EnergyConfig\n",
    "from core.video_processor import visualize_detections\n",
    "\n",
    "# Configure method\n",
    "config = EnergyConfig(\n",
    "    weight_motion=0.3,\n",
    "    weight_interaction=0.3,\n",
    "    weight_scene_change=0.2,\n",
    "    weight_uncertainty=0.2,\n",
    "    thresholds=[2.0, 1.5, 1.0],\n",
    "    top_k=10\n",
    ")\n",
    "\n",
    "# Initialize method\n",
    "method = HierarchicalEnergyMethod(config)\n",
    "\n",
    "# Process video\n",
    "print(\"Processing video with Hierarchical Energy method...\")\n",
    "detected_events = method.process_video('data/example_video.mp4')\n",
    "\n",
    "print(f\"\\nDetected {len(detected_events)} events:\")\n",
    "for i, event in enumerate(detected_events):\n",
    "    print(f\"  Event {i+1}: {event.start_time:.2f}s - {event.end_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Results\n",
    "\n",
    "Create annotated video with detected events highlighted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load ground truth annotations\n",
    "with open('data/annotations.json', 'r') as f:\n",
    "    annotations = json.load(f)\n",
    "\n",
    "# Create visualization\n",
    "print(\"Creating visualization video...\")\n",
    "visualize_detections(\n",
    "    'data/example_video.mp4',\n",
    "    detected_events,\n",
    "    'results/videos/hierarchical_energy_demo.mp4',\n",
    "    annotations['events']\n",
    ")\n",
    "\n",
    "print(\"Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Display Results\n",
    "\n",
    "Show detected events in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "# Display output video\n",
    "Video('results/videos/hierarchical_energy_demo.mp4', width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compute Metrics\n",
    "\n",
    "Evaluate precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(detected, ground_truth, iou_threshold=0.5):\n",
    "    \"\"\"Compute precision, recall, and F1 score.\"\"\"\n",
    "    \n",
    "    def iou(window1, window2):\n",
    "        \"\"\"Intersection over union for temporal windows.\"\"\"\n",
    "        start = max(window1['start_time'], window2.start_time)\n",
    "        end = min(window1['end_time'], window2.end_time)\n",
    "        \n",
    "        if start >= end:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = end - start\n",
    "        union = (window1['end_time'] - window1['start_time'] + \n",
    "                 window2.end_time - window2.start_time - intersection)\n",
    "        \n",
    "        return intersection / union\n",
    "    \n",
    "    # Match detections to ground truth\n",
    "    tp = 0\n",
    "    matched_gt = set()\n",
    "    \n",
    "    for det in detected:\n",
    "        best_iou = 0\n",
    "        best_gt_idx = None\n",
    "        \n",
    "        for i, gt in enumerate(ground_truth):\n",
    "            if i not in matched_gt:\n",
    "                overlap = iou(gt, det)\n",
    "                if overlap > best_iou:\n",
    "                    best_iou = overlap\n",
    "                    best_gt_idx = i\n",
    "        \n",
    "        if best_iou >= iou_threshold:\n",
    "            tp += 1\n",
    "            matched_gt.add(best_gt_idx)\n",
    "    \n",
    "    fp = len(detected) - tp\n",
    "    fn = len(ground_truth) - tp\n",
    "    \n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'tp': tp,\n",
    "        'fp': fp,\n",
    "        'fn': fn\n",
    "    }\n",
    "\n",
    "# Compute metrics\n",
    "metrics = compute_metrics(detected_events, annotations['events'])\n",
    "\n",
    "print(\"\\nEvaluation Metrics:\")\n",
    "print(f\"  Precision: {metrics['precision']:.3f}\")\n",
    "print(f\"  Recall:    {metrics['recall']:.3f}\")\n",
    "print(f\"  F1 Score:  {metrics['f1']:.3f}\")\n",
    "print(f\"\\n  True Positives:  {metrics['tp']}\")\n",
    "print(f\"  False Positives: {metrics['fp']}\")\n",
    "print(f\"  False Negatives: {metrics['fn']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Compare Energy Components\n",
    "\n",
    "Visualize contribution of each energy term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Re-extract features for analysis\n",
    "all_windows = method.processor.chunk_video('data/example_video.mp4')\n",
    "all_features = method.extract_features(all_windows, level=2)\n",
    "\n",
    "# Extract feature arrays\n",
    "motion = [f['motion'] for f in all_features]\n",
    "interaction = [f['interaction'] for f in all_features]\n",
    "scene_change = [f['scene_change'] for f in all_features]\n",
    "uncertainty = [f['uncertainty'] for f in all_features]\n",
    "\n",
    "# Compute total energy\n",
    "total_energy = method.compute_energy(all_features)\n",
    "\n",
    "# Create stacked area plot\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "\n",
    "time_points = [w.start_time for w in all_windows]\n",
    "\n",
    "ax.fill_between(time_points, 0, motion, alpha=0.5, label='Motion')\n",
    "ax.fill_between(time_points, motion, np.array(motion) + np.array(interaction), \n",
    "                alpha=0.5, label='Interaction')\n",
    "ax.plot(time_points, total_energy, 'k-', linewidth=2, label='Total Energy')\n",
    "\n",
    "# Mark detected events\n",
    "for event in detected_events:\n",
    "    ax.axvspan(event.start_time, event.end_time, alpha=0.3, color='red', label='Detected')\n",
    "\n",
    "# Mark ground truth\n",
    "for gt in annotations['events']:\n",
    "    ax.axvspan(gt['start_time'], gt['end_time'], alpha=0.2, color='blue', \n",
    "              linestyle='--', label='Ground Truth')\n",
    "\n",
    "ax.set_xlabel('Time (s)', fontsize=12)\n",
    "ax.set_ylabel('Energy', fontsize=12)\n",
    "ax.set_title('Event Energy Over Time', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right')\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/figures/energy_timeline.pdf', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Next Steps\n",
    "\n",
    "- Try different configuration parameters\n",
    "- Compare with other methods (see `02_full_comparison.ipynb`)\n",
    "- Run on your own videos\n",
    "- Tune weights for your specific domain\n",
    "\n",
    "**Full documentation**: [README.md](../README.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
